{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- re-calculate DT and LR model performance using different evaluation metrics (e.g., confusion matrix, precision/- recall/f1, roc_auc_score/roc_curve)\n",
    "- interpret the model performance to understand the advantage and disadvantage of each model\n",
    "- apply gridsearchcv to find the most suitable hyperparameters for each model\n",
    "- with the best hyperparameter setting you find in last step, apply KFold cross validation to validate your model performance on each fold\n",
    "[optional] explore one of the ensemble learning methods to improve your model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview\n",
    "\n",
    "## Target Variable:\n",
    "- belief: category, the religious belief status of the individual, used to classify Atheism(0) and Theism(1).\n",
    "\n",
    "## Continuous/Numeric Variables:\n",
    "- age: int64, the age of the user.\n",
    "- height: float64, the height of the user in centimeters.\n",
    "- income: int64, the income of the user.\n",
    "- seriousness_degree: float64, the degree of seriousness about religion. (0 = unspecified ,1-4 = not serious to very serious)\n",
    "\n",
    "## Categorical Variables:\n",
    "- status: category, relationship status.\n",
    "- sex: category, gender.\n",
    "- orientation: category, sexual orientation.\n",
    "- body_type: category, body type.\n",
    "- diet: category, dietary habits.\n",
    "- drinks: category, alcohol consumption habits.\n",
    "- drugs: category, drug usage.\n",
    "- education: category, educational attainment.\n",
    "- ethnicity: category, ethnic background.\n",
    "- job: category, employment description.\n",
    "- location: category, user location.\n",
    "- offspring: category, children status.\n",
    "- pets: category, pet preferences.\n",
    "- religion: category, religious background.\n",
    "- sign: category, astrological symbol.\n",
    "- smokes: category, smoking consumption.\n",
    "- speaks: category, language spoken.\n",
    "- education_clean: category, cleaned and simplified education information.\n",
    "- education_final: category, finalized education information after processing.\n",
    "- cleaned_religion: category, cleaned version of religious background.\n",
    "\n",
    "## Text Variables:\n",
    "- My self summary: object, a summary written by the user about themselves.\n",
    "- What I’m doing with my life: object, user's description of their current life status.\n",
    "- I’m really good at: object, what the user describes as their strengths.\n",
    "- The first thing people usually notice about me: object, what the user thinks people notice about them first.\n",
    "- Favorite books, movies, show, music, and food: object, user's favorites in books, movies, shows, music, and food.\n",
    "- The six things I could never do without: object, things the user considers essential in their life.\n",
    "- I spend a lot of time thinking about: object, topics the user often thinks about.\n",
    "- On a typical Friday night I am: object, user's typical activities on a Friday night.\n",
    "- The most private thing I am willing to admit: object, something personal the user is willing to share.\n",
    "- You should message me if…: object, user's criteria for others to contact them.\n",
    "- merged_profile: object, combined text from all essay sections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection: \n",
    "### Bagging - RF\n",
    "### &\n",
    "### Regression, generally not the best suit for classification task\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning and visualization libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, the goal is to predict one's religious belief based on the following features:\n",
    "\n",
    "#8 Catgorical:\n",
    "diet(clean), \n",
    "drinks,\n",
    "etnicity(clean), \n",
    "education(final), \n",
    "status, \n",
    "drugs, \n",
    "smokes, \n",
    "orientation,\n",
    "job(clean)\n",
    "\n",
    "#2 Num:\n",
    "age, \n",
    "height\n",
    "\n",
    "$ Tagert:\n",
    "belief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16597, 74)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>belief</th>\n",
       "      <th>diet_clean_anything</th>\n",
       "      <th>diet_clean_halal</th>\n",
       "      <th>diet_clean_kosher</th>\n",
       "      <th>diet_clean_other</th>\n",
       "      <th>diet_clean_unknown</th>\n",
       "      <th>diet_clean_vegan</th>\n",
       "      <th>...</th>\n",
       "      <th>job_clean_military</th>\n",
       "      <th>job_clean_other</th>\n",
       "      <th>job_clean_political</th>\n",
       "      <th>job_clean_rather not say</th>\n",
       "      <th>job_clean_retired</th>\n",
       "      <th>job_clean_sales</th>\n",
       "      <th>job_clean_science</th>\n",
       "      <th>job_clean_student</th>\n",
       "      <th>job_clean_transportation</th>\n",
       "      <th>job_clean_unemployed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16592</th>\n",
       "      <td>59602</td>\n",
       "      <td>29</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16593</th>\n",
       "      <td>59603</td>\n",
       "      <td>27</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16594</th>\n",
       "      <td>59609</td>\n",
       "      <td>25</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16595</th>\n",
       "      <td>59614</td>\n",
       "      <td>59</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16596</th>\n",
       "      <td>59616</td>\n",
       "      <td>42</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16597 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  age  height  belief  diet_clean_anything  diet_clean_halal  \\\n",
       "0               7   31    65.0       1                  1.0               0.0   \n",
       "1               9   37    65.0       0                  1.0               0.0   \n",
       "2              11   28    72.0       1                  1.0               0.0   \n",
       "3              13   30    66.0       1                  1.0               0.0   \n",
       "4              14   29    62.0       1                  1.0               0.0   \n",
       "...           ...  ...     ...     ...                  ...               ...   \n",
       "16592       59602   29    75.0       1                  1.0               0.0   \n",
       "16593       59603   27    68.0       0                  0.0               0.0   \n",
       "16594       59609   25    61.0       0                  1.0               0.0   \n",
       "16595       59614   59    62.0       1                  0.0               0.0   \n",
       "16596       59616   42    71.0       1                  1.0               0.0   \n",
       "\n",
       "       diet_clean_kosher  diet_clean_other  diet_clean_unknown  \\\n",
       "0                    0.0               0.0                 0.0   \n",
       "1                    0.0               0.0                 0.0   \n",
       "2                    0.0               0.0                 0.0   \n",
       "3                    0.0               0.0                 0.0   \n",
       "4                    0.0               0.0                 0.0   \n",
       "...                  ...               ...                 ...   \n",
       "16592                0.0               0.0                 0.0   \n",
       "16593                0.0               0.0                 0.0   \n",
       "16594                0.0               0.0                 0.0   \n",
       "16595                0.0               0.0                 1.0   \n",
       "16596                0.0               0.0                 0.0   \n",
       "\n",
       "       diet_clean_vegan  ...  job_clean_military  job_clean_other  \\\n",
       "0                   0.0  ...                 0.0              0.0   \n",
       "1                   0.0  ...                 0.0              0.0   \n",
       "2                   0.0  ...                 0.0              0.0   \n",
       "3                   0.0  ...                 0.0              0.0   \n",
       "4                   0.0  ...                 0.0              1.0   \n",
       "...                 ...  ...                 ...              ...   \n",
       "16592               0.0  ...                 0.0              0.0   \n",
       "16593               0.0  ...                 0.0              0.0   \n",
       "16594               0.0  ...                 0.0              1.0   \n",
       "16595               0.0  ...                 0.0              0.0   \n",
       "16596               0.0  ...                 0.0              0.0   \n",
       "\n",
       "       job_clean_political  job_clean_rather not say  job_clean_retired  \\\n",
       "0                      0.0                       0.0                0.0   \n",
       "1                      0.0                       0.0                0.0   \n",
       "2                      0.0                       0.0                0.0   \n",
       "3                      0.0                       0.0                0.0   \n",
       "4                      0.0                       0.0                0.0   \n",
       "...                    ...                       ...                ...   \n",
       "16592                  0.0                       0.0                0.0   \n",
       "16593                  0.0                       0.0                0.0   \n",
       "16594                  0.0                       0.0                0.0   \n",
       "16595                  0.0                       0.0                0.0   \n",
       "16596                  0.0                       0.0                0.0   \n",
       "\n",
       "       job_clean_sales  job_clean_science  job_clean_student  \\\n",
       "0                  0.0                0.0                0.0   \n",
       "1                  0.0                0.0                1.0   \n",
       "2                  0.0                0.0                0.0   \n",
       "3                  1.0                0.0                0.0   \n",
       "4                  0.0                0.0                0.0   \n",
       "...                ...                ...                ...   \n",
       "16592              0.0                1.0                0.0   \n",
       "16593              0.0                0.0                0.0   \n",
       "16594              0.0                0.0                0.0   \n",
       "16595              1.0                0.0                0.0   \n",
       "16596              0.0                0.0                0.0   \n",
       "\n",
       "       job_clean_transportation  job_clean_unemployed  \n",
       "0                           0.0                   0.0  \n",
       "1                           0.0                   0.0  \n",
       "2                           0.0                   0.0  \n",
       "3                           0.0                   0.0  \n",
       "4                           0.0                   0.0  \n",
       "...                         ...                   ...  \n",
       "16592                       0.0                   0.0  \n",
       "16593                       0.0                   0.0  \n",
       "16594                       0.0                   0.0  \n",
       "16595                       0.0                   0.0  \n",
       "16596                       0.0                   0.0  \n",
       "\n",
       "[16597 rows x 74 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training data\n",
    "# this data contains the encoded and cleaned data and TARGET variable 'belief'\n",
    "df_X = pd.read_csv('/Users/adhdtreamentii/Desktop/UChicago 2024/UChicago Winter 24/MACSS-30100/Final/data/encoded_cleanedcat_dataX.csv')\n",
    "\n",
    "print(df_X.shape)\n",
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training shape:(16597, 72)\n",
      "target shape:(16597, 1)\n"
     ]
    }
   ],
   "source": [
    "df_y = df_X[['belief']]\n",
    "\n",
    "df_X = df_X.drop(columns=['belief'])\n",
    "df_X = df_X.drop(columns=['Unnamed: 0']) # drop the index column from uncleaned data\n",
    "\n",
    "print(f'training shape:{df_X.shape}')\n",
    "print(f'target shape:{df_y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11617, 72), (4980, 72))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create split with Sklearn\n",
    "df_X_train, df_X_test, df_y_train, df_y_test  = train_test_split(df_X, df_y, test_size = 0.3,random_state = 42)\n",
    "\n",
    "# View the training and testing feature matrix \n",
    "df_X_train.shape, df_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>diet_clean_anything</th>\n",
       "      <th>diet_clean_halal</th>\n",
       "      <th>diet_clean_kosher</th>\n",
       "      <th>diet_clean_other</th>\n",
       "      <th>diet_clean_unknown</th>\n",
       "      <th>diet_clean_vegan</th>\n",
       "      <th>diet_clean_vegetarian</th>\n",
       "      <th>drinks_desperately</th>\n",
       "      <th>...</th>\n",
       "      <th>job_clean_military</th>\n",
       "      <th>job_clean_other</th>\n",
       "      <th>job_clean_political</th>\n",
       "      <th>job_clean_rather not say</th>\n",
       "      <th>job_clean_retired</th>\n",
       "      <th>job_clean_sales</th>\n",
       "      <th>job_clean_science</th>\n",
       "      <th>job_clean_student</th>\n",
       "      <th>job_clean_transportation</th>\n",
       "      <th>job_clean_unemployed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13450</th>\n",
       "      <td>23</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10118</th>\n",
       "      <td>49</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>24</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12239</th>\n",
       "      <td>34</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>24</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>23</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11964</th>\n",
       "      <td>24</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>40</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>25</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>41</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11617 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  height  diet_clean_anything  diet_clean_halal  diet_clean_kosher  \\\n",
       "13450   23    66.0                  0.0               0.0                0.0   \n",
       "10118   49    66.0                  0.0               0.0                0.0   \n",
       "1432    24    66.0                  1.0               0.0                0.0   \n",
       "12239   34    71.0                  1.0               0.0                0.0   \n",
       "7612    24    62.0                  0.0               0.0                0.0   \n",
       "...    ...     ...                  ...               ...                ...   \n",
       "11284   23    74.0                  0.0               0.0                0.0   \n",
       "11964   24    73.0                  1.0               0.0                0.0   \n",
       "5390    40    72.0                  0.0               0.0                0.0   \n",
       "860     25    64.0                  0.0               0.0                0.0   \n",
       "15795   41    67.0                  0.0               0.0                0.0   \n",
       "\n",
       "       diet_clean_other  diet_clean_unknown  diet_clean_vegan  \\\n",
       "13450               0.0                 1.0               0.0   \n",
       "10118               0.0                 0.0               0.0   \n",
       "1432                0.0                 0.0               0.0   \n",
       "12239               0.0                 0.0               0.0   \n",
       "7612                1.0                 0.0               0.0   \n",
       "...                 ...                 ...               ...   \n",
       "11284               0.0                 1.0               0.0   \n",
       "11964               0.0                 0.0               0.0   \n",
       "5390                0.0                 1.0               0.0   \n",
       "860                 0.0                 1.0               0.0   \n",
       "15795               0.0                 0.0               0.0   \n",
       "\n",
       "       diet_clean_vegetarian  drinks_desperately  ...  job_clean_military  \\\n",
       "13450                    0.0                 0.0  ...                 0.0   \n",
       "10118                    1.0                 0.0  ...                 0.0   \n",
       "1432                     0.0                 0.0  ...                 0.0   \n",
       "12239                    0.0                 0.0  ...                 0.0   \n",
       "7612                     0.0                 0.0  ...                 1.0   \n",
       "...                      ...                 ...  ...                 ...   \n",
       "11284                    0.0                 0.0  ...                 0.0   \n",
       "11964                    0.0                 0.0  ...                 0.0   \n",
       "5390                     0.0                 0.0  ...                 0.0   \n",
       "860                      0.0                 0.0  ...                 0.0   \n",
       "15795                    1.0                 0.0  ...                 0.0   \n",
       "\n",
       "       job_clean_other  job_clean_political  job_clean_rather not say  \\\n",
       "13450              0.0                  0.0                       0.0   \n",
       "10118              0.0                  0.0                       0.0   \n",
       "1432               0.0                  0.0                       0.0   \n",
       "12239              0.0                  0.0                       0.0   \n",
       "7612               0.0                  0.0                       0.0   \n",
       "...                ...                  ...                       ...   \n",
       "11284              0.0                  0.0                       0.0   \n",
       "11964              0.0                  0.0                       0.0   \n",
       "5390               0.0                  0.0                       0.0   \n",
       "860                0.0                  0.0                       0.0   \n",
       "15795              0.0                  0.0                       0.0   \n",
       "\n",
       "       job_clean_retired  job_clean_sales  job_clean_science  \\\n",
       "13450                0.0              0.0                0.0   \n",
       "10118                0.0              0.0                0.0   \n",
       "1432                 0.0              0.0                0.0   \n",
       "12239                0.0              0.0                1.0   \n",
       "7612                 0.0              0.0                0.0   \n",
       "...                  ...              ...                ...   \n",
       "11284                0.0              0.0                0.0   \n",
       "11964                0.0              0.0                0.0   \n",
       "5390                 0.0              0.0                1.0   \n",
       "860                  0.0              1.0                0.0   \n",
       "15795                0.0              0.0                0.0   \n",
       "\n",
       "       job_clean_student  job_clean_transportation  job_clean_unemployed  \n",
       "13450                0.0                       0.0                   0.0  \n",
       "10118                0.0                       0.0                   0.0  \n",
       "1432                 1.0                       0.0                   0.0  \n",
       "12239                0.0                       0.0                   0.0  \n",
       "7612                 0.0                       0.0                   0.0  \n",
       "...                  ...                       ...                   ...  \n",
       "11284                0.0                       0.0                   0.0  \n",
       "11964                0.0                       0.0                   0.0  \n",
       "5390                 0.0                       0.0                   0.0  \n",
       "860                  0.0                       0.0                   0.0  \n",
       "15795                0.0                       0.0                   0.0  \n",
       "\n",
       "[11617 rows x 72 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>belief</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14027</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4789</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14042</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14766</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5211</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7864</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13769</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10866</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13586</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4980 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       belief\n",
       "14027       1\n",
       "4789        1\n",
       "14042       0\n",
       "14766       1\n",
       "5211        1\n",
       "...       ...\n",
       "7864        1\n",
       "13769       1\n",
       "2186        0\n",
       "10866       1\n",
       "13586       0\n",
       "\n",
       "[4980 rows x 1 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest classifier\n",
    "\n",
    "In this task, I will use the same data to:\n",
    "- train a [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "- report its performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.737"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "rf_clf = RandomForestClassifier(n_estimators = 60, criterion = 'entropy', random_state = 42)\n",
    "\n",
    "# train RFC\n",
    "rf_clf.fit(df_X_train, df_y_train['belief'])\n",
    "\n",
    "# evaluate the random forest classifier on test set \n",
    "float(\"{:.3f}\".format(rf_clf.score(df_X_test, df_y_test['belief'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aidi/lib/python3.9/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.757\n"
     ]
    }
   ],
   "source": [
    "# modify the model to reduce overfitting\n",
    "\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=50,        # number of trees in the forest\n",
    "    criterion='entropy',    \n",
    "    max_depth=20,         # the maximum depth of the tree\n",
    "    min_samples_split=2,    # the minimum number of samples required to split an internal node\n",
    "    min_samples_leaf=3,     # the minimum number of samples required to be at a leaf node\n",
    "    bootstrap=True,         # whether bootstrap samples are used when building trees\n",
    "    random_state=42        \n",
    ")\n",
    "\n",
    "rf_clf.fit(df_X_train, df_y_train)\n",
    "\n",
    "test_accuracy = rf_clf.score(df_X_test, df_y_test)\n",
    "print(\"Testing Accuracy: {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4980\n",
      "4980\n",
      "[1 1 0 ... 0 1 0]\n",
      "[1 1 1 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# prediction results of the testing set\n",
    "y_pred = rf_clf.predict(df_X_test)\n",
    "\n",
    "print(len(df_y_test))\n",
    "# reshape the y_test to match the shape of y_pred, 1d array\n",
    "y_true = np.array(df_y_test).reshape(1, len(df_y_test))[0]\n",
    "\n",
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atheism(0) and Theism(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 400\n",
      "False Positives: 1016\n",
      "False Negatives: 193\n",
      "True Positives: 3371\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(df_y_test, y_pred)\n",
    "\n",
    "# extract TN, FP, FN, TP\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Negatives (TN): 400\n",
    "\n",
    "This means that the model correctly predicted 400 instances as Atheism (0), where the actual label was indeed Atheism. In other words, these are the cases where the model correctly identified the absence of Theism.\n",
    "False Positives (FP): 1016\n",
    "\n",
    "These are instances where the model incorrectly predicted Theism (1), but the actual label was Atheism (0). This is a type of error where the model 'falsely' identified Theism when it wasn't actually present.\n",
    "False Negatives (FN): 193\n",
    "\n",
    "This count indicates that there were 193 instances where the model predicted Atheism (0), but the actual label was Theism (1). These are missed opportunities by the model to identify Theism, hence 'false negatives'.\n",
    "True Positives (TP): 3371\n",
    "\n",
    "This large number shows that the model correctly predicted 3371 instances as Theism (1), and these instances were indeed Theism in reality. This is a strong indicator that the model is quite effective in identifying cases of Theism.\n",
    "Interpreting these numbers, I can see that the model is quite good at identifying Theism (True Positives are high), but it also makes a significant number of False Positive errors. This suggests that while the model is adept at recognizing instances of Theism, it also tends to mistakenly classify some Atheism instances as Theism. The relatively high number of False Positives compared to False Negatives could indicate a bias in the model towards predicting Theism.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.28      0.40      1416\n",
      "           1       0.77      0.95      0.85      3564\n",
      "\n",
      "    accuracy                           0.76      4980\n",
      "   macro avg       0.72      0.61      0.62      4980\n",
      "weighted avg       0.74      0.76      0.72      4980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7572289156626506"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Atheism (0.40): The F1-score, which is a balance between precision and recall, is quite low. This indicates a poor performance for Atheism, largely driven by its low recall.\n",
    "\n",
    "Recall (0.28): Only 28% of actual Atheism instances were correctly identified by the model. This low recall indicates that the model is missing a large number of Atheism cases, probably due to the imbalance towards Theism (1416 vs. 3564).\n",
    "\n",
    "The support values show the imbalance in the dataset, with significantly more instances of Theism (3564) than Atheism (1416)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is biased towards predicting Theism, likely due to the imbalance in the dataset.\n",
    "While the model shows promise(good acc), especially in identifying Theism, its performance on Atheism is suboptimal, highlighting the need for extra effort that address the data imbalance and improve overall model fairness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26926777, 0.73073223],\n",
       "       [0.10152921, 0.89847079],\n",
       "       [0.16170282, 0.83829718],\n",
       "       ...,\n",
       "       [0.52500618, 0.47499382],\n",
       "       [0.11491035, 0.88508965],\n",
       "       [0.21161054, 0.78838946]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs = rf_clf.predict_proba(df_X_test)\n",
    "y_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(df_y_test, y_probs[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       inf, 0.99216088, 0.97494377, ..., 0.24221019, 0.23660484,\n",
       "       0.19929599])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7682493286601102"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc = roc_auc_score(df_y_test, y_probs[:, 1])\n",
    "\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label='ROC')\n",
    "plt.plot([0, 1], [0, 1], color='darkgrey', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curve shows a decent separation between the positive and negative classes, as it bows towards the top-left corner of the plot. This indicates that the model has a good measure of separability and is able to distinguish between the two classes better than random guess (p =0.5)\n",
    "\n",
    "An AUC score of 0.7682 is quite respectable. It suggests that there is a 76.82% chance that the classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one. \n",
    "\n",
    "the ROC curve and AUC score indicate that the model has a fair predictive ability, but with an AUC score of approximately 0.7682, there's potential to enhance the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model performance with bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion about Pros and Cons of different evaluation\n",
    "\n",
    "Confusion Matrix:\n",
    "- Pros: offers a overall inspect of model performance, we can interpret TP,FP,FN,TN. This provides a better understanding of a model's capalilities in detecing the different catgories.\n",
    "- Cons: the scores in CM could be misleading. Espcially when the dataset is imblanced. For example, if the data number of a certain catgory is way more than the other one, this might suggests that the model only perform well on the main catgory.\n",
    "\n",
    "Precision/Recall/F1:\n",
    "- P: percision evaluates the accuracy of the positive predictions, meaning the ratio of correctly predicted positive observations to the total predicted positive observations\n",
    "- Recall: recall = tp / (tp + fn), recall evaluates the ability of the model to identify positive observations\n",
    "F1: F1 = 2 * (precision * recall) / (precision + recall) # F1 score is the weighted average of the precision and recall\n",
    "- Cons: High precision can be achieved at the expense of recall and vice versa. F1-score can sometimes be misleading if one class is much easier to predict than the other, or if the dataset is imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear models for classification: LogisticRegression \n",
    "Firstly, Logistic Regression is specifically designed for binary classification, as it models the probability of a binary outcome using a logistic function, ensuring that the predicted values are sensibly confined between 0 and 1. This is crucial for binary classification tasks where the output is categorical (e.g.,theism/atheism). In contrast, linear models, which predict continuous values, are NOT naturally suited for predicting probabilities and require additional steps to threshold the output for classification. Polynomial regression, while capable of modeling more complex relationships than linear models, still suffers from the same limitation in a binary classification context. \n",
    " Logistic Regression also offers a straightforward interpretation of the relationship between features and the probability of outcomes, which is less intuitive in polynomial models due to their complexity. Furthermore, Logistic Regression can be easily extended to handle multi-class classification problems, making it a better choice for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aidi/lib/python3.9/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(random_state=0, solver='liblinear', penalty='l1', C=1.0).fit(df_X_train, df_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7636222776964793"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training accuracy\n",
    "lr_clf.score(df_X_train, df_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7602409638554217"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing accuracy\n",
    "lr_clf.score(df_X_test, df_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.117, 0.883],\n",
       "       [0.141, 0.859],\n",
       "       [0.202, 0.798]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(lr_clf.predict_proba(df_X_test[:3]),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 457  959]\n",
      " [ 235 3329]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.32      0.43      1416\n",
      "           1       0.78      0.93      0.85      3564\n",
      "\n",
      "    accuracy                           0.76      4980\n",
      "   macro avg       0.72      0.63      0.64      4980\n",
      "weighted avg       0.74      0.76      0.73      4980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr_clf.predict(df_X_test)\n",
    "print(confusion_matrix(df_y_test, y_pred))\n",
    "\n",
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(df_y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training accuracy and testing accuracy indicate that the model performance is pretty consistent, so the model is not overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lr_clf Discussion:\n",
    " The recall for classifying the 0-class (the minority class) is unusually low. This is a common issue in imbalanced datasets. The model, having been exposed to more instances of class 1, becomes better at identifying class 1 and less effective at recognizing class 0. As a result, even if the overall accuracy of the model seems high, its ability to correctly identify instances of the minority class (class 0) is compromised, leading to a low recall for that class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistics Regression Vs. Random Forrest:\n",
    "- In short, no clear winner.\n",
    "\n",
    "Reflecting on the performance metrics of my Logistic Regression (LR) and Random Forest (RF) models, I observe that both have their merits. The LR model appears slightly more balanced in terms of precision and recall for the minority class, class 0, with a modestly higher F1-score. This suggests that LR is somewhat more adept at correctly identifying the class 0 instances, which is important in my context of an imbalanced dataset. On the other hand, the RF model demonstrates superior recall for the majority class, class 1, but this could be partly due to the class imbalance and not necessarily indicative of better performance.\n",
    "\n",
    "The accuracy of both models is comparable, which makes it challenging to choose one over the other solely based on this metric. Given that the macro and weighted averages of the F1-scores are also similar, there is no clear winner. However, considering the complexity and interpretability, the LR model is simpler and offers better insights into the relationship between features and the target variable, which is highly valuable to me.\n",
    "\n",
    "Moving forward to GridSearch. However, because RF has a larger number of hyperparameters that can be tuned, such as the number of trees, maximum depth, and minimum samples per leaf, it might exhibit a more significant improvement after a grid search. This could potentially enhance its performance and perhaps even surpass the current slight edge held by LR. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV\n",
    "- search for the best hyperparameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Convert the target variable to 1d array\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df_y_train \u001b[39m=\u001b[39m df_y_train[\u001b[39m'\u001b[39;49m\u001b[39mbelief\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mravel()\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(df_y_train)\n\u001b[1;32m      7\u001b[0m df_y_test \u001b[39m=\u001b[39m df_y_test[\u001b[39m'\u001b[39m\u001b[39mbelief\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mravel()\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# Convert the target variable to 1d array\n",
    "\n",
    "\n",
    "df_y_train = df_y_train['belief'].values.ravel()\n",
    "print(df_y_train)\n",
    "\n",
    "df_y_test = df_y_test['belief'].values.ravel()\n",
    "print(df_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "please ignore this Error message because I accidently clicked twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 1 0]\n",
      "[1 1 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(df_y_train)\n",
    "\n",
    "print(df_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'bootstrap': False, 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [10, 20, 50],\n",
    "    'max_depth': [10, 20], # the maximum depth of the tree， None would cause overfitting based on prior experience in last hw\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# scoring method\n",
    "scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rf_clf, param_grid=rf_param_grid, scoring=scorer, cv=5)\n",
    "\n",
    "# grid search\n",
    "grid_search.fit(df_X_train, df_y_train)\n",
    "\n",
    "# get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best parameters found: \", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(bootstrap=False, max_depth=20, min_samples_leaf=2,\n",
       "                       min_samples_split=5, n_estimators=50, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(bootstrap=False, max_depth=20, min_samples_leaf=2,\n",
       "                       min_samples_split=5, n_estimators=50, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, max_depth=20, min_samples_leaf=2,\n",
       "                       min_samples_split=5, n_estimators=50, random_state=42)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_bootstrap',\n",
       " 'param_max_depth',\n",
       " 'param_min_samples_leaf',\n",
       " 'param_min_samples_split',\n",
       " 'param_n_estimators',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'split3_test_score',\n",
       " 'split4_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(grid_search.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7571665297189002"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there's no a obvious change in grid_search result,(in order to save computing time, I didn't apply full parameter settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "original model accuracy: 0.76\n",
    "\n",
    "parameter tuning accuracy: 0.75\n",
    "\n",
    "original settings:  \n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=50,        # number of trees in the forest\n",
    "    criterion='entropy',    \n",
    "    max_depth=20,         # the maximum depth of the tree\n",
    "    min_samples_split=2,    # the minimum number of samples required to split an internal node\n",
    "    min_samples_leaf=3,     # the minimum number of samples required to be at a leaf node\n",
    "    bootstrap=True,         # whether bootstrap samples are used when building trees\n",
    "    random_state=42        \n",
    ")\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the tuning effect is not suffient, perhaps we are close to reach the limit of model performance (marginal effect)\n",
    "Moving forward, I will apply my original setting to K-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold Accuracy Scores: [0.76979346 0.75860585 0.7533362  0.76409815 0.74042187]\n",
      "Average KFold Accuracy: 0.7572511063872982\n"
     ]
    }
   ],
   "source": [
    "rf_clf_best = RandomForestClassifier(\n",
    "    n_estimators=50,\n",
    "    criterion='entropy',\n",
    "    max_depth=20,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=3,\n",
    "    bootstrap=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "cv_scores = cross_val_score(rf_clf_best, df_X_train, df_y_train, cv=kf)\n",
    "\n",
    "# output the accuracy scores for each fold\n",
    "print(\"KFold Accuracy Scores:\", cv_scores)\n",
    "\n",
    "# average accuracy score\n",
    "print(\"Average KFold Accuracy:\", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "\n",
    "The lack of significant improvement in model performance after hyperparameter optimization using GridSearchCV reveals some key insights. \n",
    "- Firstly, it might indicate that my current model is approaching its performance limit, and further optimization may not yield substantial gains. In such cases, I might need to consider changing the model architecture or introducing more feature data to hope for improved performance.\n",
    "\n",
    "- Secondly, I've noticed that my model struggles with correctly identifying class 0 (Atheism), particularly evident in the low recall. This suggests that my model has difficulties handling the minority class in an imbalanced dataset. Such imbalance could lead to an overestimated accuracy, as the model tends to predict the dominant class. Therefore, I think my next plan should include training the model with a more balanced dataset. By selecting roughly equal numbers of class 0 and class 1 data, I can assess the model's performance on both classes more fairly.\n",
    "\n",
    "This approach should help reduce the oversight of the minority class and might improve the recall for class 0. Additionally, a model trained on a balanced dataset might have better generalization capabilities and more accurately reflect the model's performance in real-world applications.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aidi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
